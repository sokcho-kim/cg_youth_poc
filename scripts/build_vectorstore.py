import json
import os
from typing import List, Dict
from sentence_transformers import SentenceTransformer
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from langchain.embeddings import HuggingFaceEmbeddings
import glob

class PolicyVectorizer:
    def __init__(self, embedding_model_name: str = "BM-K/KoSimCSE-roberta"):
        """
        ì •ì±… ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ëŠ” í´ë˜ìŠ¤
        
        Args:
            embedding_model_name: ì„ë² ë”© ëª¨ë¸ëª… (ê¸°ë³¸ê°’: KoSimCSE)
        """
        self.embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)
        self.vectorstore = None
        
    def load_policy_data(self, data_dir: str = "data/processed") -> List[Dict]:
        """
        JSON íŒŒì¼ë“¤ì—ì„œ ì •ì±… ë°ì´í„° ë¡œë“œ
        
        Args:
            data_dir: ì •ì±… JSON íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
            
        Returns:
            ì •ì±… ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        policy_files = glob.glob(os.path.join(data_dir, "*.json"))
        policies = []
        
        for file_path in policy_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    policy = json.load(f)
                    policies.append(policy)
                print(f"âœ… ë¡œë“œë¨: {os.path.basename(file_path)}")
            except Exception as e:
                print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {file_path} - {e}")
                
        print(f"ğŸ“Š ì´ {len(policies)}ê°œ ì •ì±… ë¡œë“œ ì™„ë£Œ")
        return policies
    
    def create_policy_text(self, policy: Dict) -> str:
        """
        ì •ì±… ë°ì´í„°ë¥¼ ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            policy: ì •ì±… ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸
        """
        text_parts = []
        
        # ì œëª© (ê°€ì¥ ì¤‘ìš”)
        if policy.get("title"):
            text_parts.append(f"ì œëª©: {policy['title']}")
        
        # ì •ì±… ì†Œê°œ
        if policy.get("introduction"):
            text_parts.append(f"ì •ì±… ì†Œê°œ: {policy['introduction']}")
        
        # ì§€ì› ë‚´ìš©
        if policy.get("content"):
            text_parts.append(f"ì§€ì› ë‚´ìš©: {policy['content']}")
        
        # ì •ì±… ìœ í˜•
        if policy.get("policy_type"):
            text_parts.append(f"ì •ì±… ìœ í˜•: {policy['policy_type']}")
        
        # ì£¼ê´€ ê¸°ê´€
        if policy.get("agency"):
            text_parts.append(f"ì£¼ê´€ ê¸°ê´€: {policy['agency']}")
        
        # ì‹ ì²­ìê²© (ì—°ë ¹, í•™ë ¥ ë“±)
        if policy.get("age_range"):
            text_parts.append(f"ì—°ë ¹: {policy['age_range']}")
        if policy.get("education"):
            text_parts.append(f"í•™ë ¥: {policy['education']}")
        if policy.get("employment_status"):
            text_parts.append(f"ì·¨ì—…ìƒíƒœ: {policy['employment_status']}")
        
        # ì‹ ì²­ê¸°ê°„
        if policy.get("apply_start") and policy.get("apply_end"):
            text_parts.append(f"ì‹ ì²­ê¸°ê°„: {policy['apply_start']} ~ {policy['apply_end']}")
        
        # ì§€ì›ê·œëª¨
        if policy.get("support_scale"):
            text_parts.append(f"ì§€ì›ê·œëª¨: {policy['support_scale']}")
        
        return "\n".join(text_parts)
    
    def create_metadata(self, policy: Dict) -> Dict:
        """
        ì •ì±… ë©”íƒ€ë°ì´í„° ìƒì„±
        
        Args:
            policy: ì •ì±… ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        metadata = {
            "policy_id": policy.get("plcyBizId", ""),
            "title": policy.get("title", ""),
            "policy_type": policy.get("policy_type", ""),
            "agency": policy.get("agency", ""),
            "age_range": policy.get("age_range", ""),
            "education": policy.get("education", ""),
            "employment_status": policy.get("employment_status", ""),
            "apply_start": policy.get("apply_start", ""),
            "apply_end": policy.get("apply_end", ""),
            "support_scale": policy.get("support_scale", ""),
            "page_url": policy.get("page_url", ""),
            "application_site": policy.get("application_site", "")
        }
        
        # ë¹ˆ ê°’ ì œê±°
        metadata = {k: v for k, v in metadata.items() if v}
        return metadata
    
    def vectorize_policies(self, policies: List[Dict], persist_directory: str = "vectorstore"):
        """
        ì •ì±…ë“¤ì„ ë²¡í„°í™”í•˜ì—¬ ChromaDBì— ì €ì¥
        
        Args:
            policies: ì •ì±… ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            persist_directory: ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        documents = []
        
        for policy in policies:
            # ì •ì±… í…ìŠ¤íŠ¸ ìƒì„±
            text = self.create_policy_text(policy)
            if not text.strip():
                print(f"âš ï¸ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ: {policy.get('plcyBizId', 'Unknown')}")
                continue
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = self.create_metadata(policy)
            
            # Document ê°ì²´ ìƒì„±
            doc = Document(
                page_content=text,
                metadata=metadata
            )
            documents.append(doc)
            
            print(f"ğŸ“ ë²¡í„°í™” ì¤€ë¹„: {policy.get('title', 'Unknown')[:30]}...")
        
        print(f"ğŸ” ì´ {len(documents)}ê°œ ë¬¸ì„œ ë²¡í„°í™” ì‹œì‘...")
        
        # ChromaDBì— ì €ì¥
        self.vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embedding_model,
            persist_directory=persist_directory
        )
        
        # ì €ì¥
        self.vectorstore.persist()
        print(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ: {persist_directory}")
        
        return self.vectorstore
    
    def test_search(self, query: str, k: int = 3):
        """
        ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        """
        if not self.vectorstore:
            print("âŒ ë²¡í„°ìŠ¤í† ì–´ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
        results = self.vectorstore.similarity_search(query, k=k)
        
        for i, doc in enumerate(results, 1):
            print(f"\nğŸ“‹ ê²°ê³¼ {i}:")
            print(f"   ì œëª©: {doc.metadata.get('title', 'N/A')}")
            print(f"   ì •ì±…ID: {doc.metadata.get('policy_id', 'N/A')}")
            print(f"   ì •ì±…ìœ í˜•: {doc.metadata.get('policy_type', 'N/A')}")
            print(f"   ì—°ë ¹: {doc.metadata.get('age_range', 'N/A')}")
            print(f"   ë‚´ìš© ì¼ë¶€: {doc.page_content[:100]}...")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì •ì±… ë²¡í„°í™” ì‹œì‘...")
    
    # ë²¡í„°ë¼ì´ì € ì´ˆê¸°í™”
    vectorizer = PolicyVectorizer()
    
    # ì •ì±… ë°ì´í„° ë¡œë“œ
    policies = vectorizer.load_policy_data()
    
    if not policies:
        print("âŒ ë¡œë“œí•  ì •ì±… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë²¡í„°í™” ë° ì €ì¥
    vectorstore = vectorizer.vectorize_policies(policies)
    
    # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
    print("\nğŸ§ª ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
    test_queries = [
        "30ëŒ€ ë¬´ì§ì ì·¨ì—… ì§€ì›",
        "ì²­ë…„ ì°½ì—… ì§€ì›",
        "í•™ë ¥ ì œí•œì—†ëŠ” ì¼ìë¦¬",
        "ì„œìš¸ì‹œ ì²­ë…„ ì •ì±…"
    ]
    
    for query in test_queries:
        vectorizer.test_search(query)
        print("\n" + "="*50)

if __name__ == "__main__":
    main() 